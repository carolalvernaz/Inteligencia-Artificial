{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OlLk-oh3qNj",
        "outputId": "94e7c769-c704-4099-d6ce-8dbbfbc965bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Escolha a função lógica (AND, OR, XOR): XOR\n",
            "Digite o número de entradas booleanas (ex: 2, 3, 10): 4\n",
            "\n",
            "Resultados obtidos pela rede MLP com backpropagation:\n",
            "Entrada: [0 0 0 0], Esperado: 0, Previsto: 0\n",
            "Entrada: [0 0 0 1], Esperado: 1, Previsto: 1\n",
            "Entrada: [0 0 1 0], Esperado: 1, Previsto: 1\n",
            "Entrada: [0 0 1 1], Esperado: 0, Previsto: 0\n",
            "Entrada: [0 1 0 0], Esperado: 1, Previsto: 1\n",
            "Entrada: [0 1 0 1], Esperado: 0, Previsto: 0\n",
            "Entrada: [0 1 1 0], Esperado: 0, Previsto: 0\n",
            "Entrada: [0 1 1 1], Esperado: 1, Previsto: 1\n",
            "Entrada: [1 0 0 0], Esperado: 1, Previsto: 1\n",
            "Entrada: [1 0 0 1], Esperado: 0, Previsto: 0\n",
            "Entrada: [1 0 1 0], Esperado: 0, Previsto: 0\n",
            "Entrada: [1 0 1 1], Esperado: 1, Previsto: 1\n",
            "Entrada: [1 1 0 0], Esperado: 0, Previsto: 0\n",
            "Entrada: [1 1 0 1], Esperado: 1, Previsto: 1\n",
            "Entrada: [1 1 1 0], Esperado: 1, Previsto: 1\n",
            "Entrada: [1 1 1 1], Esperado: 0, Previsto: 0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from itertools import product\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivada(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "def gerar_dados(n, funcao):\n",
        "    X = np.array(list(product([0, 1], repeat=n)))\n",
        "    if funcao == 'AND':\n",
        "        y = np.array([[int(np.all(xi))] for xi in X])\n",
        "    elif funcao == 'OR':\n",
        "        y = np.array([[int(np.any(xi))] for xi in X])\n",
        "    elif funcao == 'XOR':\n",
        "        y = np.array([[int(np.sum(xi) % 2)] for xi in X])\n",
        "    else:\n",
        "        raise ValueError(\"Função lógica inválida. Use AND, OR ou XOR.\")\n",
        "    return X, y\n",
        "\n",
        "class MLP:\n",
        "    def __init__(self, n_entradas, n_oculta=None, taxa_aprendizado=0.5):\n",
        "        self.n_entradas = n_entradas\n",
        "        self.n_oculta = n_oculta or (2 * n_entradas + 1)\n",
        "        self.n_saida = 1\n",
        "        self.taxa_aprendizado = taxa_aprendizado\n",
        "\n",
        "        self.w_entrada_oculta = np.random.uniform(-1, 1, (self.n_entradas, self.n_oculta))\n",
        "        self.b_oculta = np.zeros((1, self.n_oculta))\n",
        "\n",
        "        self.w_oculta_saida = np.random.uniform(-1, 1, (self.n_oculta, self.n_saida))\n",
        "        self.b_saida = np.zeros((1, self.n_saida))\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.entrada = X\n",
        "        self.in_oculta = np.dot(X, self.w_entrada_oculta) + self.b_oculta\n",
        "        self.out_oculta = sigmoid(self.in_oculta)\n",
        "\n",
        "        self.in_saida = np.dot(self.out_oculta, self.w_oculta_saida) + self.b_saida\n",
        "        self.saida = sigmoid(self.in_saida)\n",
        "        return self.saida\n",
        "\n",
        "    def backward(self, y):\n",
        "        erro_saida = y - self.saida\n",
        "        delta_saida = erro_saida * sigmoid_derivada(self.saida)\n",
        "\n",
        "        erro_oculta = delta_saida.dot(self.w_oculta_saida.T)\n",
        "        delta_oculta = erro_oculta * sigmoid_derivada(self.out_oculta)\n",
        "\n",
        "        self.w_oculta_saida += self.taxa_aprendizado * self.out_oculta.T.dot(delta_saida)\n",
        "        self.b_saida += self.taxa_aprendizado * np.sum(delta_saida, axis=0, keepdims=True)\n",
        "\n",
        "        self.w_entrada_oculta += self.taxa_aprendizado * self.entrada.T.dot(delta_oculta)\n",
        "        self.b_oculta += self.taxa_aprendizado * np.sum(delta_oculta, axis=0, keepdims=True)\n",
        "\n",
        "        return np.mean(np.abs(erro_saida))\n",
        "\n",
        "    def treinar(self, X, y, max_iter=10000, tolerancia=1e-4):\n",
        "        for _ in range(max_iter):\n",
        "            self.forward(X)\n",
        "            erro = self.backward(y)\n",
        "            if erro < tolerancia:\n",
        "                break\n",
        "\n",
        "    def prever(self, X):\n",
        "        return (self.forward(X) > 0.5).astype(int)\n",
        "\n",
        "def main():\n",
        "    funcao = input(\"Escolha a função lógica (AND, OR, XOR): \").strip().upper()\n",
        "    n = int(input(\"Digite o número de entradas booleanas (ex: 2, 3, 10): \"))\n",
        "\n",
        "    X, y = gerar_dados(n, funcao)\n",
        "    rede = MLP(n_entradas=n)\n",
        "    rede.treinar(X, y)\n",
        "\n",
        "    print(\"\\nResultados obtidos pela rede MLP com backpropagation:\")\n",
        "    for xi, yi in zip(X, y):\n",
        "        previsto = rede.prever(np.array([xi]))[0][0]\n",
        "        print(f\"Entrada: {xi}, Esperado: {yi[0]}, Previsto: {previsto}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula complementar: implementação de funções de ativação alternativas\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Função sigmoide (já usada no código principal)\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivada(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Função tangente hiperbólica (tanh)\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def tanh_derivada(x):\n",
        "    return 1 - x ** 2\n",
        "\n",
        "# Função ReLU (Rectified Linear Unit)\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_derivada(x):\n",
        "    return np.where(x > 0, 1, 0)\n",
        "\n",
        "# Teste simples para visualizar saídas das funções de ativação para alguns valores de entrada\n",
        "entradas = np.array([-2.0, -1.0, 0.0, 1.0, 2.0])\n",
        "\n",
        "print(\"Entradas:\", entradas)\n",
        "print(\"Sigmoide:\", sigmoid(entradas))\n",
        "print(\"Tanh:\", tanh(entradas))\n",
        "print(\"ReLU:\", relu(entradas))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHr1SsnQCjqQ",
        "outputId": "dcd9f2e8-fcc6-47cd-b2eb-fd078ec2bf5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entradas: [-2. -1.  0.  1.  2.]\n",
            "Sigmoide: [0.11920292 0.26894142 0.5        0.73105858 0.88079708]\n",
            "Tanh: [-0.96402758 -0.76159416  0.          0.76159416  0.96402758]\n",
            "ReLU: [0. 0. 0. 1. 2.]\n"
          ]
        }
      ]
    }
  ]
}